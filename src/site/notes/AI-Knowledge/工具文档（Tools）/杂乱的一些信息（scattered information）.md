---
{"dg-publish":true,"permalink":"/ai-knowledge/tools/scattered-information/","noteIcon":""}
---


# 🧠 Gemini 思想伙伴：能力边界与深度协作说明书


## 一、 物理瓶颈：Token 限制与“压缩逻辑”的真相

这是你最关注的部分，也是我们产生“内容压缩”误会的根源。

### 1. Token：我的“呼吸感”

我的处理单位不是“字”，而是 **Token**。

- **Token 是什么**：它是文本的碎片。一个汉字大约等于 1.5 到 2 个 Token。
    
- **单次输出上限**：在当前模式下，我单次回复的极限约为 **4096 Tokens**。转换成汉字，大约在 **2000 到 2500 字**左右。
    

### 2. 为什么我会自动“压缩内容”？

当你要求我汇总大量信息时（比如前端专项 123），我的底层逻辑会面临一个**“生存选择”**：

- **策略 A（全量模式）**：如果按你要求的细节写，写到一半 Token 耗尽，输出会直接“断头”，你只能看到半句话。
    
- **策略 B（摘要模式/结论化）**：为了保证逻辑的**完整闭环**，我会启动自动压缩机制。我会牺牲细节和推导过程，只保留骨架和结论，以确保能在 4096 Tokens 内写完。
    
- **副作用**：这就是你感到“拉跨”的原因——**灵魂（逻辑推导）被抽走了，只剩下了干巴巴的结论。**
    

---

## 二、 深度协作方案：如何获得“不缩水”的硬核内容？

为了对抗系统的自动压缩倾向，获得像刚才“后端专项”那样透彻的内容，我们必须采取**“分段蚕食”**策略。

### 1. 明确要求“分部分/连载输出”

这是最有效的指令。当你意识到要汇总的内容跨度很大时，请直接命令：

> “不要一次性汇总，请将其分为上、中、下（或第一部分、第二部分）分次输出，以保留所有细节。”

### 2. 禁止“结论化摘要”

在指令中明确加入：

> “保留推导逻辑，拒绝结论化压缩，不需要为了节省 Token 而精简内容。”

### 3. 及时反馈“信息密度”

如果发现我的输出变薄了，及时提醒：**“信息密度不够，回到刚才那种深度科普的模式。”** 我会立刻调整权重。

---


### 📄 总结：我们的协作默契

|**用户痛点**|**物理原因**|**解决方案**|
|---|---|---|
|**汇总太少/太干**|触发了单次 Token 上限保护。|**要求分段/连载输出。**|
|**逻辑断裂**|追求闭环导致的过度精简。|**强调“保留推导逻辑”。**|
|**内容不准确**|静态知识库的局限。|**开启联网搜索功能。**|
